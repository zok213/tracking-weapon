{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ VT-MOT Far-View Gated Mid-Fusion Training\n",
                "\n",
                "**Strategy:** Transfer Learning V2 (Near‚ÜíFar Domain Adaptation)  \n",
                "**Model:** YOLOv11x-RGBT with GatedSpatialFusion_V3  \n",
                "**Dataset:** vtmot_far (284k images, single class: person)  \n",
                "\n",
                "## Prerequisites\n",
                "1. Upload dataset zips as Kaggle Datasets:\n",
                "   - `vtmot-far-train`: vtmot_far_train_part{1..4}.zip\n",
                "   - `vtmot-far-valtest`: vtmot_far_val_test_part{1..2}.zip\n",
                "2. Upload `vtmot_weights.zip` to Google Drive, set sharing to 'Anyone with link'\n",
                "3. Enable **GPU** accelerator\n",
                "4. Set persistence to **Files**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 1: Clone Repository & Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, subprocess, sys\n",
                "\n",
                "WORK_DIR = \"/kaggle/working\"\n",
                "REPO_DIR = os.path.join(WORK_DIR, \"tracking-weapon\")\n",
                "\n",
                "# Clone repo\n",
                "if not os.path.exists(REPO_DIR):\n",
                "    !git clone --depth 1 https://github.com/zok213/tracking-weapon.git {REPO_DIR}\n",
                "    print(\"‚úÖ Repository cloned.\")\n",
                "else:\n",
                "    print(\"‚úÖ Repository already exists.\")\n",
                "\n",
                "# Install modified ultralytics (with GatedSpatialFusion_V3)\n",
                "!pip install -e {REPO_DIR}/YOLOv11-RGBT --quiet --no-deps\n",
                "!pip install einops>=0.7 timm>=0.9 efficientnet-pytorch>=0.7.1 albumentations>=1.0.3 thop psutil gdown --quiet\n",
                "\n",
                "# Verify\n",
                "import torch\n",
                "print(f\"\\nPyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
                "\n",
                "from ultralytics import YOLO\n",
                "from ultralytics.nn.modules.block import GatedSpatialFusion_V3\n",
                "print(\"‚úÖ GatedSpatialFusion_V3 loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 2: Download Weights from Google Drive\n",
                "\n",
                "**Instructions:** Upload `vtmot_weights.zip` (395MB) to Google Drive ‚Üí Share ‚Üí Anyone with link ‚Üí Copy the file ID from the URL."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gdown, zipfile\n",
                "\n",
                "# ============================================================\n",
                "# ‚ö†Ô∏è  PASTE YOUR GOOGLE DRIVE FILE ID HERE\n",
                "# From URL: https://drive.google.com/file/d/<FILE_ID>/view\n",
                "# ============================================================\n",
                "GDRIVE_FILE_ID = \"PASTE_YOUR_FILE_ID_HERE\"  # <-- CHANGE THIS!\n",
                "# ============================================================\n",
                "\n",
                "WEIGHTS_DIR = os.path.join(WORK_DIR, \"weights\")\n",
                "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
                "\n",
                "weights_zip = os.path.join(WEIGHTS_DIR, \"vtmot_weights.zip\")\n",
                "best_pt = os.path.join(WEIGHTS_DIR, \"best_near_gated_phase1.pt\")\n",
                "\n",
                "if not os.path.exists(best_pt):\n",
                "    print(\"üì• Downloading weights from Google Drive...\")\n",
                "    gdown.download(id=GDRIVE_FILE_ID, output=weights_zip, quiet=False)\n",
                "    \n",
                "    print(\"üì¶ Extracting weights...\")\n",
                "    with zipfile.ZipFile(weights_zip, 'r') as zf:\n",
                "        zf.extractall(WEIGHTS_DIR)\n",
                "    os.remove(weights_zip)\n",
                "    print(\"‚úÖ Weights extracted.\")\n",
                "else:\n",
                "    print(\"‚úÖ Weights already exist.\")\n",
                "\n",
                "# List weights\n",
                "for f in os.listdir(WEIGHTS_DIR):\n",
                "    fp = os.path.join(WEIGHTS_DIR, f)\n",
                "    if f.endswith('.pt'):\n",
                "        print(f\"   {f}: {os.path.getsize(fp) / (1024**2):.0f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 3: Extract Dataset from Kaggle Inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob, zipfile\n",
                "from tqdm import tqdm\n",
                "\n",
                "DATASET_DIR = os.path.join(WORK_DIR, \"datasets/vtmot_far\")\n",
                "os.makedirs(DATASET_DIR, exist_ok=True)\n",
                "\n",
                "KAGGLE_INPUT = \"/kaggle/input\"\n",
                "\n",
                "# Auto-discover all vtmot zip files from inputs\n",
                "all_zips = glob.glob(os.path.join(KAGGLE_INPUT, \"**\", \"*.zip\"), recursive=True)\n",
                "vtmot_zips = [z for z in all_zips if \"vtmot_far\" in os.path.basename(z)]\n",
                "\n",
                "if not vtmot_zips:\n",
                "    # Try broader search\n",
                "    vtmot_zips = all_zips\n",
                "    print(f\"‚ö†Ô∏è No 'vtmot_far' zips found. Found {len(all_zips)} total zips:\")\n",
                "    for z in all_zips:\n",
                "        print(f\"   {z} ({os.path.getsize(z)/(1024**3):.1f} GB)\")\n",
                "\n",
                "print(f\"\\nüì¶ Found {len(vtmot_zips)} dataset zip files:\")\n",
                "for z in sorted(vtmot_zips):\n",
                "    print(f\"   {os.path.basename(z)}: {os.path.getsize(z)/(1024**3):.1f} GB\")\n",
                "\n",
                "# Check if already extracted\n",
                "train_images = os.path.join(DATASET_DIR, \"images\", \"train\")\n",
                "if os.path.exists(train_images) and len(os.listdir(train_images)) > 1000:\n",
                "    print(f\"\\n‚úÖ Dataset already extracted ({len(os.listdir(train_images))} train images)\")\n",
                "else:\n",
                "    for z in tqdm(sorted(vtmot_zips), desc=\"Extracting\"):\n",
                "        print(f\"   üì¶ {os.path.basename(z)}...\")\n",
                "        with zipfile.ZipFile(z, 'r') as zf:\n",
                "            zf.extractall(DATASET_DIR)\n",
                "    print(\"‚úÖ All zips extracted.\")\n",
                "\n",
                "# Verify structure\n",
                "print(\"\\nüìä Dataset Verification:\")\n",
                "for split in [\"train\", \"val\", \"test\"]:\n",
                "    img_dir = os.path.join(DATASET_DIR, \"images\", split)\n",
                "    lbl_dir = os.path.join(DATASET_DIR, \"labels\", split)\n",
                "    n_imgs = len(os.listdir(img_dir)) if os.path.exists(img_dir) else 0\n",
                "    n_lbls = len(os.listdir(lbl_dir)) if os.path.exists(lbl_dir) else 0\n",
                "    status = \"‚úÖ\" if n_imgs > 0 else \"‚ùå\"\n",
                "    print(f\"   {status} {split}: {n_imgs:,} images, {n_lbls:,} labels\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 4: Create Dataset YAML"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "yaml_path = os.path.join(DATASET_DIR, \"far_view_kaggle.yaml\")\n",
                "\n",
                "yaml_content = f\"\"\"path: {DATASET_DIR}\n",
                "train: images/train\n",
                "val: images/val\n",
                "test: images/test\n",
                "names:\n",
                "  0: person\n",
                "\"\"\"\n",
                "\n",
                "with open(yaml_path, 'w') as f:\n",
                "    f.write(yaml_content)\n",
                "\n",
                "print(f\"‚úÖ Dataset YAML created: {yaml_path}\")\n",
                "print(f\"\\nContents:\")\n",
                "print(yaml_content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 5: Setup Training Components\n",
                "\n",
                "MCFTrainer with Gate Supervision + Gradient Clipping + bbox_decode patch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from pathlib import Path\n",
                "from ultralytics import YOLO\n",
                "from ultralytics.models.yolo.detect import DetectionTrainer\n",
                "from ultralytics.utils import DEFAULT_CFG\n",
                "from ultralytics.utils import loss as loss_module\n",
                "\n",
                "# Add repo to path for gate_supervision, visualize_gates\n",
                "sys.path.insert(0, REPO_DIR)\n",
                "\n",
                "# v2.7 bbox_decode device patch\n",
                "_original_bbox_decode = loss_module.v8DetectionLoss.bbox_decode\n",
                "def _patched_bbox_decode(self, anchor_points, pred_dist):\n",
                "    if self.use_dfl:\n",
                "        if self.proj.device != pred_dist.device:\n",
                "            self.proj = self.proj.to(pred_dist.device)\n",
                "    return _original_bbox_decode(self, anchor_points, pred_dist)\n",
                "loss_module.v8DetectionLoss.bbox_decode = _patched_bbox_decode\n",
                "print(\"[OK] bbox_decode device patch applied.\")\n",
                "\n",
                "\n",
                "class MCFTrainer(DetectionTrainer):\n",
                "    \"\"\"Custom trainer with Gated Fusion + Gate Supervision.\"\"\"\n",
                "    \n",
                "    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None, mcf_model=None):\n",
                "        self._mcf_model = mcf_model\n",
                "        super().__init__(cfg, overrides, _callbacks)\n",
                "    \n",
                "    def setup_model(self):\n",
                "        model = self._mcf_model if self._mcf_model is not None else super().setup_model()\n",
                "        count = 0\n",
                "        try:\n",
                "            from ultralytics.nn.modules.block import GatedSpatialFusion_V3\n",
                "            modules = model.modules() if hasattr(model, 'modules') else model.model.modules()\n",
                "            for m in modules:\n",
                "                if isinstance(m, GatedSpatialFusion_V3):\n",
                "                    m.export_gates = True\n",
                "                    count += 1\n",
                "        except ImportError:\n",
                "            pass\n",
                "        print(f\"[MCFTrainer] Gate export enabled on {count} layers.\")\n",
                "        \n",
                "        if self._mcf_model is not None:\n",
                "            self.model = model\n",
                "            self.model.to(self.device)\n",
                "            self.model.args = self.args\n",
                "            return self.model\n",
                "        return model\n",
                "\n",
                "    def get_loss(self):\n",
                "        loss = super().get_loss()\n",
                "        try:\n",
                "            from gate_supervision import GatedDetectionLoss\n",
                "            print(\"[MCFTrainer] Gate supervision loss active.\")\n",
                "            return GatedDetectionLoss(self.model, loss)\n",
                "        except ImportError:\n",
                "            print(\"[MCFTrainer] gate_supervision not found, standard loss.\")\n",
                "            return loss\n",
                "\n",
                "\n",
                "def on_train_start(trainer):\n",
                "    \"\"\"Gradient clipping callback.\"\"\"\n",
                "    if hasattr(trainer, 'optimizer') and trainer.optimizer is not None:\n",
                "        orig_step = trainer.optimizer.step\n",
                "        def clipped_step(closure=None):\n",
                "            torch.nn.utils.clip_grad_norm_(trainer.model.parameters(), max_norm=10.0)\n",
                "            return orig_step(closure)\n",
                "        trainer.optimizer.step = clipped_step\n",
                "        print(\"‚ö° Gradient Clipping (norm=10.0) applied.\")\n",
                "\n",
                "print(\"‚úÖ MCFTrainer + callbacks defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 6: Load Model Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = 0\n",
                "resume_flag = False\n",
                "\n",
                "runs_dir = os.path.join(WORK_DIR, \"runs\")\n",
                "project_dir = os.path.join(runs_dir, \"far_gated_deployment\")\n",
                "run_name = \"far_view_gated_kaggle\"\n",
                "last_ckpt = os.path.join(project_dir, run_name, \"weights\", \"last.pt\")\n",
                "\n",
                "# Weight selection priority: resume > near best.pt > FLIR > random\n",
                "best_pt_path = os.path.join(WEIGHTS_DIR, \"best_near_gated_phase1.pt\")\n",
                "flir_pt_path = None\n",
                "for f in os.listdir(WEIGHTS_DIR):\n",
                "    if \"FLIR\" in f and f.endswith(\".pt\"):\n",
                "        flir_pt_path = os.path.join(WEIGHTS_DIR, f)\n",
                "\n",
                "if os.path.exists(last_ckpt):\n",
                "    print(f\"[RESUME] Loading checkpoint: {last_ckpt}\")\n",
                "    model = YOLO(last_ckpt)\n",
                "    resume_flag = True\n",
                "elif os.path.exists(best_pt_path):\n",
                "    print(f\"[TRANSFER] Loading near-view best.pt: {best_pt_path}\")\n",
                "    model = YOLO(best_pt_path)\n",
                "    print(\"‚úÖ Transfer Learning V2: Near‚ÜíFar domain adaptation\")\n",
                "    print(\"   Gated Fusion layers pre-trained from near-view!\")\n",
                "elif flir_pt_path and os.path.exists(flir_pt_path):\n",
                "    print(f\"[FALLBACK] Using FLIR pretrained: {flir_pt_path}\")\n",
                "    model_yaml = os.path.join(REPO_DIR, \"YOLOv11-RGBT/ultralytics/cfg/models/11-RGBT/yolo11x-RGBT-gated-v3.yaml\")\n",
                "    model = YOLO(model_yaml)\n",
                "    ckpt = torch.load(flir_pt_path, map_location='cpu')\n",
                "    if 'model' in ckpt:\n",
                "        chk_sd = ckpt['model'].state_dict()\n",
                "        mdl_sd = model.model.state_dict()\n",
                "        filtered = {k: v for k, v in chk_sd.items() if k in mdl_sd and v.shape == mdl_sd[k].shape}\n",
                "        if filtered:\n",
                "            model.model.load_state_dict(filtered, strict=False)\n",
                "            print(f\"‚úÖ Transferred {len(filtered)} FLIR layers.\")\n",
                "else:\n",
                "    print(\"[INIT] No pretrained weights found. Random init.\")\n",
                "    model_yaml = os.path.join(REPO_DIR, \"YOLOv11-RGBT/ultralytics/cfg/models/11-RGBT/yolo11x-RGBT-gated-v3.yaml\")\n",
                "    model = YOLO(model_yaml)\n",
                "\n",
                "print(f\"\\nModel ready. Resume: {resume_flag}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 7: üöÄ Launch Training\n",
                "\n",
                "- **30 epochs**, SGD + Cosine LR\n",
                "- **batch=8** (Kaggle 16GB VRAM safe)\n",
                "- Strong augmentations for far-view small objects\n",
                "- Checkpoints saved every 5 epochs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "    'model': last_ckpt if resume_flag else 'yolo11x.pt',\n",
                "    'data': yaml_path,\n",
                "    'epochs': 30,\n",
                "    'imgsz': 640,\n",
                "    'batch': 8,\n",
                "    'device': device,\n",
                "    'use_simotm': 'RGBRGB6C',\n",
                "    'channels': 6,\n",
                "    'pairs_rgb_ir': ['_rgb_', '_ir_'],\n",
                "    'optimizer': 'SGD',\n",
                "    'lr0': 0.005,\n",
                "    'lrf': 0.01,\n",
                "    'cos_lr': True,\n",
                "    'momentum': 0.937,\n",
                "    'weight_decay': 0.0005,\n",
                "    'warmup_epochs': 2,\n",
                "    'warmup_bias_lr': 0.05,\n",
                "    'mosaic': 1.0,\n",
                "    'mixup': 0.15,\n",
                "    'copy_paste': 0.1,\n",
                "    'scale': 0.7,\n",
                "    'close_mosaic': 10,\n",
                "    'patience': 15,\n",
                "    'save_period': 5,\n",
                "    'freeze': None,\n",
                "    'project': project_dir,\n",
                "    'name': run_name,\n",
                "    'exist_ok': True,\n",
                "    'cache': 'disk',\n",
                "    'workers': 2,\n",
                "    'resume': resume_flag,\n",
                "}\n",
                "\n",
                "print(\"=\" * 70)\n",
                "print(\"üöÄ FAR-VIEW GATED MID-FUSION ‚Äî DEPLOYMENT TRAINING\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"  GPU:       {torch.cuda.get_device_name(0)}\")\n",
                "print(f\"  Dataset:   {yaml_path}\")\n",
                "print(f\"  Epochs:    {config['epochs']}\")\n",
                "print(f\"  Batch:     {config['batch']}\")\n",
                "print(f\"  Optimizer: SGD (lr=0.005, cosine)\")\n",
                "print(f\"  Output:    {project_dir}/{run_name}\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "trainer = MCFTrainer(\n",
                "    overrides=config,\n",
                "    mcf_model=None if resume_flag else model.model\n",
                ")\n",
                "trainer.add_callback(\"on_train_start\", on_train_start)\n",
                "trainer.train()\n",
                "\n",
                "print(\"\\n‚úÖ Training Complete!\")\n",
                "print(f\"   Best weights: {project_dir}/{run_name}/weights/best.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 8: Save & Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "output_dir = \"/kaggle/working/output\"\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "# Copy best weights\n",
                "best_weight = os.path.join(project_dir, run_name, \"weights\", \"best.pt\")\n",
                "last_weight = os.path.join(project_dir, run_name, \"weights\", \"last.pt\")\n",
                "\n",
                "for src, name in [(best_weight, \"best_far_gated.pt\"), (last_weight, \"last_far_gated.pt\")]:\n",
                "    if os.path.exists(src):\n",
                "        dest = os.path.join(output_dir, name)\n",
                "        shutil.copy2(src, dest)\n",
                "        print(f\"‚úÖ {name}: {os.path.getsize(dest)/(1024**2):.0f} MB\")\n",
                "\n",
                "# Copy results CSV\n",
                "results_csv = os.path.join(project_dir, run_name, \"results.csv\")\n",
                "if os.path.exists(results_csv):\n",
                "    shutil.copy2(results_csv, os.path.join(output_dir, \"results.csv\"))\n",
                "    print(\"‚úÖ results.csv saved.\")\n",
                "\n",
                "# Copy training plots\n",
                "for plot in ['results.png', 'confusion_matrix.png', 'PR_curve.png', 'F1_curve.png']:\n",
                "    src = os.path.join(project_dir, run_name, plot)\n",
                "    if os.path.exists(src):\n",
                "        shutil.copy2(src, os.path.join(output_dir, plot))\n",
                "        print(f\"‚úÖ {plot} saved.\")\n",
                "\n",
                "print(f\"\\nüéØ All outputs in: {output_dir}/\")\n",
                "print(\"   Download from Kaggle Output tab.\")\n",
                "print(f\"\\nFiles:\")\n",
                "for f in sorted(os.listdir(output_dir)):\n",
                "    fp = os.path.join(output_dir, f)\n",
                "    print(f\"   {f}: {os.path.getsize(fp)/(1024**2):.1f} MB\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}